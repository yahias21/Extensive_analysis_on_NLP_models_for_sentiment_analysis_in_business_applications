{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "top_semanticMiner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88i2trkYWQCd"
      },
      "source": [
        "# A complete profile for sentiment analysis model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bm1hVHTWQCf"
      },
      "source": [
        "## Models Ideas:\n",
        "1. Use of custom models for different categories (tech, food, books,...) to be automatically (using context classfication) or manually selected(by the client). *(different datasets applied)*\n",
        "2. Run multiple models per dataset and derive weighted average results.\n",
        "3. Developing a layered classification **use *fast/slow* classification** (divide the dataset using confidence index to strong and weak groups; the weak group will be analysed further using Roberta model).\n",
        "4. Aspect based analysis **(attach sentiment to specific aspects rather than sentence/opinion)** and word cloud **(for word frequencies)** to show insights of the reviews. (Amazon comprehend model)\n",
        "5. Use of lemmatization, opinion unit extractor, subjectivity index and multiclass classification(love, sad, angry,...) for better accuracy and data enrichment.\n",
        "6. Test of a sent-ngrams lexion sentiment analysis **(SO-CAL)**.\n",
        "7. Use of client dataset to fine-tune the model. (Ideation phase)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sodUERMXWQCg"
      },
      "source": [
        "## Datasets used:\n",
        "1. Twitter airline \n",
        "2. IMDB \n",
        "3. Yelp (preprocessing phase)\n",
        "4. Amazon \n",
        "5. 140sentiment twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnyUKCIYWQCh"
      },
      "source": [
        "## Implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUP9j8SCWQCh"
      },
      "source": [
        "### Imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIt7_lKp0h-",
        "pycharm": {
          "is_executing": true
        }
      },
      "source": [
        "# Install the transformers library\n",
        "!pip install transformers\n",
        "!pip install vaderSentiment\n",
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRHTAIVJWQCh",
        "pycharm": {
          "is_executing": true
        }
      },
      "source": [
        "from textblob import TextBlob as tb\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "from textblob import Blobber\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from flair.data import Sentence\n",
        "from flair.models import TextClassifier\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "# only for colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE59-3sHWQCi"
      },
      "source": [
        "### libraries implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGERbWuDWQCi",
        "pycharm": {
          "is_executing": true
        }
      },
      "source": [
        "def metric(true,predict):\n",
        "    analytics=[]\n",
        "    #metrics.classification_report(true,predict)\n",
        "    analytics.append(round(metrics.accuracy_score(true,predict),2))\n",
        "    analytics.append(round(metrics.precision_score(true,predict,average='weighted'),2))\n",
        "    analytics.append(round(metrics.recall_score(true,predict,average='weighted'),2))\n",
        "    analytics.append(round(metrics.f1_score(true,predict,average='weighted'),2))\n",
        "    return analytics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXdp_EIMWQCj",
        "pycharm": {
          "is_executing": true
        }
      },
      "source": [
        "# class modelDataset:\n",
        "#     def __init__(self, tokenized_texts):\n",
        "#         self.tokenized_texts = tokenized_texts\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.tokenized_texts[\"input_ids\"])\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return {k: v[idx] for k, v in self.tokenized_texts.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT28MtWhWQCj",
        "pycharm": {
          "is_executing": true
        }
      },
      "source": [
        "def textblobPattern(text):\n",
        "    sentiment = []\n",
        "    start=time.time()\n",
        "    for sentence in text:\n",
        "        sent = tb(sentence).polarity\n",
        "        if sent > 0:\n",
        "            sentiment.append(1)\n",
        "        elif sent < 0:\n",
        "            sentiment.append(-1)\n",
        "        else:\n",
        "            sentiment.append(0)\n",
        "    end=time.time()\n",
        "    tm=(end-start)/len(text)\n",
        "    return tm,sentiment\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "5bXICqyDSWyi"
      },
      "source": [
        "def textblobNB(text):\n",
        "    sentimentV, sentimentT = [], []\n",
        "    tbnb = Blobber(analyzer=NaiveBayesAnalyzer())\n",
        "    for sentence in text:\n",
        "        ts = tbnb(sentence).sentiment\n",
        "    return sentimentV, sentimentT\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "rNQPMZjcSWyj"
      },
      "source": [
        "def vader(text):\n",
        "    sentiment = []\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    start=time.time()\n",
        "    for sentence in text:\n",
        "        vs = analyzer.polarity_scores(sentence)['compound']\n",
        "        if (vs > 0.5):\n",
        "            sentiment.append(1)\n",
        "        elif (vs < -0.5):\n",
        "            sentiment.append(-1)\n",
        "        else:\n",
        "            sentiment.append(0)\n",
        "    end = time.time()\n",
        "    tm = (end - start) / len(text)\n",
        "    return tm, sentiment\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "FgybBaBISWyl"
      },
      "source": [
        "def flair(text):\n",
        "    classifier = TextClassifier.load('sentiment-fast')\n",
        "    # sentences = [Sentence(t) for t in text]\n",
        "    sentiment = []\n",
        "    start=time.time()\n",
        "    for phrase in text:\n",
        "        sentence = Sentence(phrase)\n",
        "        classifier.predict(sentence, mini_batch_size=32)\n",
        "        sentiment.append(1 if sentence.labels[0].value == 'POSITIVE' else -1)\n",
        "    end = time.time()\n",
        "    tm = (end - start) / len(text)\n",
        "    return tm, sentiment\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "68eb5zLBSWym"
      },
      "source": [
        "def RoBerta_large(text):\n",
        "    # tokenizer = AutoTokenizer.from_pretrained(\"siebert/sentiment-roberta-large-english\")\n",
        "    # model = AutoModelForSequenceClassification.from_pretrained(\"siebert/sentiment-roberta-large-english\")\n",
        "    # trainer = Trainer(model=model)\n",
        "    # tokenized_texts = tokenizer(text,truncation=True,padding=True)\n",
        "    # pred_dataset = modelDataset(tokenized_texts)\n",
        "    # predictions = trainer.predict(pred_dataset)\n",
        "    # preds = predictions.predictions.argmax(-1)\n",
        "    # return [-1 if x==0 else 1 for x in preds]\n",
        "    sentiment = []\n",
        "    sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")\n",
        "    start=time.time()\n",
        "    for x in text:\n",
        "        sentiment.append(1 if sentiment_analysis(x, truncation=True, padding=True)[0]['label'] == 'POSITIVE' else -1)\n",
        "    end = time.time()\n",
        "    tm = (end - start) / len(text)\n",
        "    return tm, sentiment\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "LFe_OFBmSWyn"
      },
      "source": [
        "\n",
        "def bert_base(text):\n",
        "    sentiment = []\n",
        "    sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "    start=time.time()\n",
        "    for x in text:\n",
        "        sent=  (sentiment_analysis(x, truncation=True, padding=True)[0]['label'])\n",
        "        if sent== \"1 star\":\n",
        "                sentiment.append(-1)\n",
        "        elif sent== \"2 stars\":\n",
        "                sentiment.append(-1)\n",
        "        elif sent == \"3 stars\":\n",
        "                sentiment.append(0)\n",
        "        elif sent ==\"4 stars\":\n",
        "                sentiment.append(1)\n",
        "        elif sent ==\"5 stars\":\n",
        "                sentiment.append(1)\n",
        "    end = time.time()\n",
        "    tm = (end - start) / len(text)\n",
        "    return tm, sentiment\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSdIjvU-SWyo"
      },
      "source": [
        "### Model testing: (for each dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "FXtwscKISWyo"
      },
      "source": [
        "def UsAirTw():\n",
        "    file_name = \"Datasets/usAir_tweets.csv\"\n",
        "    text_column = \"text\"\n",
        "    df = pd.read_csv(file_name)\n",
        "    df=df[:10000]\n",
        "    true = df[\"sentiment\"]\n",
        "    pred_texts = df[text_column].dropna().astype('str').tolist()\n",
        "    print(\"Metrics for usairline_tweets Dataset:\")\n",
        "    time, pred = textblobPattern(pred_texts)\n",
        "    textblobM = metric(true, pred)\n",
        "    print(f\"The textblob metrics:\\n accuracy={textblobM[0]},precision={textblobM[1]},recall={textblobM[2]},f1 score ={textblobM[3]},time per sentiment= {time}\")\n",
        "    time, pred = vader(pred_texts)\n",
        "    vaderM = metric(true, pred)\n",
        "    print(f\"The Vader metrics:\\n accuracy={vaderM[0]},precision={vaderM[1]},recall={vaderM[2]},f1 score ={vaderM[3]},time per sentiment= {time}\")\n",
        "    time, pred = flair(pred_texts)\n",
        "    flairM = metric(true, pred)\n",
        "    print(f\"The flair metrics:\\n accuracy={flairM[0]},precision={flairM[1]},recall={flairM[2]},f1 score ={flairM[3]},time per sentiment= {time}\")\n",
        "    time, pred = RoBerta_large(pred_texts)\n",
        "    robertaM = metric(true, pred)\n",
        "    print(f\"The Roberta large metrics:\\n accuracy={robertaM[0]},precision={robertaM[1]},recall={robertaM[2]},f1 score ={robertaM[3]},time per sentiment= {time}\")\n",
        "    time, pred = bert_base(pred_texts)\n",
        "    Bert = metric(true, pred)\n",
        "    print(f\"The bert multilang metrics:\\n accuracy={Bert[0]},precision={Bert[1]},recall={Bert[2]},f1 score ={Bert[3]},time per sentiment= {time}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "9dib59usSWyp"
      },
      "source": [
        "\n",
        "def yelp():\n",
        "    file_name = \"Datasets/yelp.csv\"\n",
        "    text_column = \"text\"\n",
        "    df = pd.read_csv(file_name)\n",
        "    true = df[\"sent\"]\n",
        "    pred_texts = df[text_column].dropna().astype('str').tolist()\n",
        "    print(\"Metrics for yelp sentiment:\")\n",
        "    time, pred = textblobPattern(pred_texts)\n",
        "    textblobM = metric(true, pred)\n",
        "    print(f\"The textblob metrics:\\n accuracy={textblobM[0]},precision={textblobM[1]},recall={textblobM[2]},f1 score ={textblobM[3]},time per sentiment= {time}\")\n",
        "    time, pred = vader(pred_texts)\n",
        "    vaderM = metric(true, pred)\n",
        "    print(f\"The Vader metrics:\\n accuracy={vaderM[0]},precision={vaderM[1]},recall={vaderM[2]},f1 score ={vaderM[3]},time per sentiment= {time}\")\n",
        "    time, pred = flair(pred_texts)\n",
        "    flairM = metric(true, pred)\n",
        "    print(f\"The flair metrics:\\n accuracy={flairM[0]},precision={flairM[1]},recall={flairM[2]},f1 score ={flairM[3]},time per sentiment= {time}\")\n",
        "    time, pred = RoBerta_large(pred_texts)\n",
        "    robertaM = metric(true, pred)\n",
        "    print(f\"The Roberta large metrics:\\n accuracy={robertaM[0]},precision={robertaM[1]},recall={robertaM[2]},f1 score ={robertaM[3]},time per sentiment= {time}\")\n",
        "    time, pred = bert_base(pred_texts)\n",
        "    Bert = metric(true, pred)\n",
        "    print(f\"The bert multilang metrics:\\n accuracy={Bert[0]},precision={Bert[1]},recall={Bert[2]},f1 score ={Bert[3]},time per sentiment= {time}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "s4ssBQD1SWyq"
      },
      "source": [
        "def Imdb():\n",
        "    file_name = \"Datasets/Imdb.csv\"\n",
        "    text_column = \"review\"\n",
        "    df = pd.read_csv(file_name)\n",
        "    df=df[:10000]\n",
        "    true = df[\"sentiment\"]\n",
        "    pred_texts = df[text_column].dropna().astype('str').tolist()\n",
        "    print(\"Metrics for IMDB dataset:\")\n",
        "    time, pred = textblobPattern(pred_texts)\n",
        "    textblobM = metric(true, pred)\n",
        "    print(f\"The textblob metrics:\\n accuracy={textblobM[0]},precision={textblobM[1]},recall={textblobM[2]},f1 score ={textblobM[3]},time per sentimen= t{time}\")\n",
        "    time, pred = vader(pred_texts)\n",
        "    vaderM = metric(true, pred)\n",
        "    print(f\"The Vader metrics:\\n accuracy={vaderM[0]},precision={vaderM[1]},recall={vaderM[2]},f1 score ={vaderM[3]},time per sentiment= {time}\")\n",
        "    time, pred = flair(pred_texts)\n",
        "    flairM = metric(true, pred)\n",
        "    print(f\"The flair metrics:\\n accuracy={flairM[0]},precision={flairM[1]},recall={flairM[2]},f1 score ={flairM[3]},time per sentiment= {time}\")\n",
        "    time, pred = RoBerta_large(pred_texts)\n",
        "    robertaM = metric(true, pred)\n",
        "    print(f\"The Roberta large metrics:\\n accuracy={robertaM[0]},precision={robertaM[1]},recall={robertaM[2]},f1 score ={robertaM[3]},time per sentiment= {time}\")\n",
        "    time, pred = bert_base(pred_texts)\n",
        "    Bert = metric(true, pred)\n",
        "    print(f\"The bert multilang metrics:\\n accuracy={Bert[0]},precision={Bert[1]},recall={Bert[2]},f1 score ={Bert[3]},time per sentiment= {time}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "0y_wtqcRSWyr"
      },
      "source": [
        "def t140sentiment():\n",
        "    file_name = \"/content/drive/MyDrive/140sentiment.csv\"\n",
        "    text_column = \"text\"\n",
        "    df = pd.read_csv(file_name)\n",
        "    df=df[:10000]\n",
        "    true = df[\"sent\"]\n",
        "    pred_texts = df[text_column].dropna().astype('str').tolist()\n",
        "    print(\"Metrics for sentiment140 dataset:\")\n",
        "    time, pred = textblobPattern(pred_texts)\n",
        "    textblobM = metric(true, pred)\n",
        "    print(f\"The textblob metrics:\\n accuracy={textblobM[0]},precision={textblobM[1]},recall={textblobM[2]},f1 score ={textblobM[3]},time per sentiment= {time}\")\n",
        "    time, pred = vader(pred_texts)\n",
        "    vaderM = metric(true, pred)\n",
        "    print(f\"The Vader metrics:\\n accuracy={vaderM[0]},precision={vaderM[1]},recall={vaderM[2]},f1 score ={vaderM[3]},time per sentiment= {time}\")\n",
        "    time, pred = flair(pred_texts)\n",
        "    flairM = metric(true, pred)\n",
        "    print(f\"The flair metrics:\\n accuracy={flairM[0]},precision={flairM[1]},recall={flairM[2]},f1 score ={flairM[3]},time per sentiment= {time}\")\n",
        "    time, pred = RoBerta_large(pred_texts)\n",
        "    robertaM = metric(true, pred)\n",
        "    print(f\"The Roberta large metrics:\\n accuracy={robertaM[0]},precision={robertaM[1]},recall={robertaM[2]},f1 score ={robertaM[3]},time per sentiment= {time}\")\n",
        "    time, pred = bert_base(pred_texts)\n",
        "    Bert = metric(true, pred)\n",
        "    print( f\"The bert multilang metrics:\\n accuracy={Bert[0]},precision={Bert[1]},recall={Bert[2]},f1 score ={Bert[3]},time per sentiment= {time}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "9IDwpOFmSWys"
      },
      "source": [
        "def amazon():\n",
        "    file_name = \"Datasets/amazonFoods.csv\"\n",
        "    text_column = \"Text\"\n",
        "    df = pd.read_csv(file_name)\n",
        "    df=df[:10000]\n",
        "    true = df[\"Score\"]\n",
        "    pred_texts = df[text_column].dropna().astype('str').tolist()\n",
        "    print(\"Metrics for Amazon food dataset:\")\n",
        "    time,pred=textblobPattern(pred_texts)\n",
        "    textblobM = metric(true, pred)\n",
        "    print(f\"The textblob metrics:\\n accuracy={textblobM[0]},precision={textblobM[1]},recall={textblobM[2]},f1 score ={textblobM[3]},time per sentiment= {time}\")\n",
        "    time,pred=vader(pred_texts)\n",
        "    vaderM = metric(true, pred)\n",
        "    print(f\"The Vader metrics:\\n accuracy={vaderM[0]},precision={vaderM[1]},recall={vaderM[2]},f1 score ={vaderM[3]},time per sentiment= {time}\")\n",
        "    time,pred=flair(pred_texts)\n",
        "    flairM = metric(true, pred)\n",
        "    print(f\"The flair metrics:\\n accuracy={flairM[0]},precision={flairM[1]},recall={flairM[2]},f1 score ={flairM[3]},time per sentiment= {time}\")\n",
        "    time,pred=RoBerta_large(pred_texts)\n",
        "    robertaM = metric(true, pred)\n",
        "    print(f\"The Roberta large metrics:\\n accuracy={robertaM[0]},precision={robertaM[1]},recall={robertaM[2]},f1 score ={robertaM[3]},time per sentiment= {time}\")\n",
        "    time,pred=bert_base(pred_texts)\n",
        "    Bert = metric(true, pred)\n",
        "    print(f\"The bert multilang metrics:\\n accuracy={Bert[0]},precision={Bert[1]},recall={Bert[2]},f1 score ={Bert[3]},time per sentiment= {time}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crmp0pBJSWyt"
      },
      "source": [
        "### Main:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7ngJZhTcuM-",
        "pycharm": {
          "is_executing": true
        },
        "outputId": "b0045290-c46a-425f-b3e3-b7363276254b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "UsAirTw()\n",
        "Imdb()\n",
        "t140sentiment()\n",
        "amazon()\n",
        "yelp()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for sentiment140 dataset:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The textblob metrics:\n",
            " accuracy=0.44,precision=0.69,recall=0.44,f1 score =0.52,time per sentiment= 0.0002885946273803711\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d212f9dfeeb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt140sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-c777e89ee89a>\u001b[0m in \u001b[0;36mt140sentiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# flairM = metric(true, pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# print(f\"The flair metrics:\\n accuracy={flairM[0]},precision={flairM[1]},recall={flairM[2]},f1 score ={flairM[3]},time per sentiment= {time}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoBerta_large\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mrobertaM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The Roberta large metrics:\\n accuracy={robertaM[0]},precision={robertaM[1]},recall={robertaM[2]},f1 score ={robertaM[3]},time per sentiment= {time}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0cf41ed0be27>\u001b[0m in \u001b[0;36mRoBerta_large\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msentiment_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'POSITIVE'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, return_all_scores, function_to_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mper\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mreturn_all_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_all_scores\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_all_scores\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, inputs, return_tensors)\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m         )\n\u001b[1;32m   1204\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m                 )\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    452\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMFt-OUiWQCo"
      },
      "source": [
        "## Results:\n",
        "### for UsAirlineTweets:\n",
        "- The textblob metrics:\n",
        " - accuracy=0.47, precision=0.68, recall=0.47, f1 score =0.48,time per sentiment = 0.0001\n",
        "- The Vader metrics:\n",
        " - accuracy=0.41, precision=0.73, recall=0.41, f1 score =0.4,time per sentiment = 0.0001\n",
        "- The flair metrics:\n",
        " - accuracy=0.67, precision=0.58, recall=0.67, f1 score =0.61 ,time per sentiment = 0.001\n",
        "- The Roberta large metrics:\n",
        " - accuracy=0.75, precision=0.62, recall=0.75, f1 score =0.67,time per sentiment = 0.0173\n",
        "- The bert multilang metrics:\n",
        " - accuracy=0.66, precision=0.64, recall=0.66, f1 score =0.64,time per sentiment = 0.071\n",
        " \n",
        "### for imdb:\n",
        "- The textblob metrics:\n",
        " - accuracy=0.69,precision=0.76,recall=0.69,f1 score =0.67,time per sentimenT= 0.0015\n",
        "- The Vader metrics:\n",
        " - accuracy=0.64,precision=0.75,recall=0.64,f1 score =0.67,time per sentiment= 0.0064\n",
        "- The flair metrics:\n",
        " - accuracy=0.9,precision=0.9,recall=0.9,f1 score =0.9,time per sentiment= 0.039\n",
        "- The Roberta large metrics:\n",
        " - accuracy=0.96,precision=0.96,recall=0.96,f1 score =0.96,time per sentiment= 1.29\n",
        "- The bert multilang metrics:\n",
        " - accuracy=0.78,precision=0.92,recall=0.78,f1 score =0.85,time per sentiment= 0.59\n",
        "\n",
        "### for Amazon:\n",
        "- The textblob metrics:\n",
        " - accuracy=0.79,precision=0.73,recall=0.79,f1 score =0.75,time per sentiment= 0.001\n",
        "- The Vader metrics:\n",
        " - accuracy=0.75,precision=0.79,recall=0.75,f1 score =0.75,time per sentiment= 0.001\n",
        "- The flair metrics:\n",
        " - accuracy=0.84,precision=0.82,recall=0.84,f1 score =0.82,time per sentiment= 0.013\n",
        "- The Roberta large metrics:\n",
        " - accuracy=0.89,precision=0.84,recall=0.89,f1 score =0.86,time per sentiment= 0.97\n",
        "- The bert multilang metrics:\n",
        " - accuracy=0.85,precision=0.88,recall=0.85,f1 score =0.86,time per sentiment= 0.29\n",
        "\n",
        "### for 140sentiment:\n",
        "- The textblob metrics:\n",
        " - accuracy=0.44,precision=0.7,recall=0.44,f1 score =0.52,time per sentiment= 0.00026\n",
        "- The Vader metrics:\n",
        " - accuracy=0.3,precision=0.79,recall=0.3,f1 score =0.41,time per sentiment= 0.0001\n",
        "- The flair metrics:\n",
        " - accuracy=0.7,precision=0.7,recall=0.7,f1 score =0.7,time per sentiment= 0.0031\n",
        " \n",
        "### for yelp:\n",
        "- The textblob metrics:\n",
        " - accuracy=0.68,precision=0.78,recall=0.68,f1 score =0.65,time per sentiment= 0.001\n",
        "- The Vader metrics:\n",
        " - accuracy=0.62,precision=0.83,recall=0.62,f1 score =0.63,time per sentiment= 0.002\n",
        "- The flair metrics:\n",
        " - accuracy=0.93,precision=0.93,recall=0.93,f1 score =0.93,time per sentiment= 0.022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQQ4l1NvWQCo"
      },
      "source": [
        "## Topics covered:\n",
        "- Textblob - vader - flair libraries\n",
        "- Text operations: lemmatization - tokenization - vectorization - wordnet - tagging - n-gram \n",
        "- Machine learning concepts: vector space model, k-means clustering,[ Naive Bayes, k-NN, SVM] classifiers, decision tree - random forest - transformers (word2vec and wordtree of stanford).\n",
        "- Technologies: Jupyter notebook - Google colab\n",
        "- Dataset handeling: dataset preprocessing\n",
        "- Sentiment analysis approaches\n",
        "- Handeling multiple  Deeplearning models: roBERTa - BERT - [GloVe - Fasttext - torchtext]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmNKHYLpWQCp"
      },
      "source": [
        "## References:\n",
        "- https://neptune.ai/blog/sentiment-analysis-python-textblob-vs-vader-vs-flair\n",
        "- https://towardsdatascience.com/customer-churn-accuracy-a-4-6-increase-with-feature-engineering-29bcb1b1ee8f (REVIEW)\n",
        "- https://www.analyticsvidhya.com/blog/2021/01/sentiment-analysis-vader-or-textblob/\n",
        "- https://pythonprogramming.net/sentiment-analysis-python-textblob-vader/\n",
        "- https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664\n",
        "- https://medium.com/geekculture/what-nlp-library-you-should-use-for-your-sentimental-analysis-project-bef6b357a6db\n",
        "- https://towardsdatascience.com/sentiment-analysis-comparing-3-common-approaches-naive-bayes-lstm-and-vader-ab561f834f89\n",
        "****\n",
        "* N-grams rule based model\n",
        "- https://www.sciencedirect.com/science/article/pii/S095741741830143X\n",
        "- https://github.com/sfu-discourse-lab/SO-CAL(to be reviewed)\n",
        "- https://towardsdatascience.com/text-analysis-basics-in-python-443282942ec5\n",
        "****\n",
        "- https://towardsdatascience.com/text-classification-with-state-of-the-art-nlp-library-flair-b541d7add21f"
      ]
    }
  ]
}