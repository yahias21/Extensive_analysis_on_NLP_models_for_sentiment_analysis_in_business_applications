{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble modeling on sentiment analysis models",
      "provenance": [],
      "authorship_tag": "ABX9TyOuSq2/bALPHB+cdQmtYz3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yahias21/Extensive_analysis_on_NLP_models_for_sentiment_analysis_in_business_applications/blob/master/Ensemble_modeling_on_sentiment_analysis_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCvbwATEhvMm"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import io\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statistics import mode\n",
        "from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "140PfbFqjeWH"
      },
      "source": [
        "df1=pd.read_csv(io.BytesIO(uploaded['output.csv']))\n",
        "truexg = df1[\"True\"].apply(lambda x: 0 if x==-1 else x)\n",
        "true=df1['True']\n",
        "Rob=df['RobSent'].mul(df1['RobConf'])\n",
        "FF=df['flairFSent'].mul(df1['flairFConf'])\n",
        "FA=df['flairASent'].mul(df1['flairAConf'])\n",
        "dfL= pd.concat([Rob,FF,FA],axis=1,names=['RobSent','flairFSent','flairASent'])\n",
        "df=df1[['flairFSent','flairASent','RobSent']]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCRBGaR_-Pv9"
      },
      "source": [
        "# Base models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ClIRRnhmB_y",
        "outputId": "3f39110e-157c-42e5-e015-cc366a1a3c70"
      },
      "source": [
        "print(metrics.classification_report(true,df['RobSent']))\n",
        "print(metrics.classification_report(true,df['flairFSent']))\n",
        "print(metrics.classification_report(true,df['flairASent']))\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.97      0.96      0.96     49986\n",
            "           1       0.96      0.97      0.96     50014\n",
            "\n",
            "    accuracy                           0.96    100000\n",
            "   macro avg       0.96      0.96      0.96    100000\n",
            "weighted avg       0.96      0.96      0.96    100000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.91      0.96      0.93     49986\n",
            "           1       0.95      0.90      0.93     50014\n",
            "\n",
            "    accuracy                           0.93    100000\n",
            "   macro avg       0.93      0.93      0.93    100000\n",
            "weighted avg       0.93      0.93      0.93    100000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.91      0.97      0.94     49986\n",
            "           1       0.97      0.91      0.94     50014\n",
            "\n",
            "    accuracy                           0.94    100000\n",
            "   macro avg       0.94      0.94      0.94    100000\n",
            "weighted avg       0.94      0.94      0.94    100000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7KcmAVp-Mr9"
      },
      "source": [
        "# Stacking:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVr9joeQm13n"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df, true, test_size=0.2, random_state=50,stratify=true)\n",
        "lrModel = LogisticRegression()\n",
        "xgModel = xgb.XGBRegressor(objective ='reg:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 8, alpha = 10, n_estimators = 10)\n",
        "lrModel.fit(X_train, y_train)\n",
        "xgModel.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8y7JFNwnJEA",
        "outputId": "a5aee9cb-50f0-4be1-e09f-dc657e1488c2"
      },
      "source": [
        "print(lrModel.score(X_test,y_test))\n",
        "out=lrModel.predict(X_test)\n",
        "print(metrics.classification_report(y_test,out))\n",
        "print(xgModel.score(X_test,y_test))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.96125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96      9997\n",
            "           1       0.95      0.97      0.96     10003\n",
            "\n",
            "    accuracy                           0.96     20000\n",
            "   macro avg       0.96      0.96      0.96     20000\n",
            "weighted avg       0.96      0.96      0.96     20000\n",
            "\n",
            "0.7212546926365101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3pldIcu-Gdw"
      },
      "source": [
        "# Stagging:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh3m2l81uXFn",
        "outputId": "53302463-05a9-4392-afd9-808c4940b411"
      },
      "source": [
        "sentiment = []\n",
        "for i in range(len(true)):\n",
        "    if (df1['flairFConf'].at[i]>0.9):\n",
        "      sentiment.append(df1['flairFSent'].at[i])\n",
        "    else:\n",
        "      if (df1['flairAConf'].at[i]>0.9):\n",
        "        sentiment.append(df1['flairASent'].at[i])\n",
        "      else:\n",
        "        sentiment.append(df1['RobSent'].at[i])\n",
        "print(metrics.classification_report(true,sentiment))\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.92      0.97      0.94     49986\n",
            "           1       0.97      0.92      0.94     50014\n",
            "\n",
            "    accuracy                           0.94    100000\n",
            "   macro avg       0.94      0.94      0.94    100000\n",
            "weighted avg       0.94      0.94      0.94    100000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg6zfDzP97Yp"
      },
      "source": [
        "# Voting:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PNupZjy3rps",
        "outputId": "74eb5e1e-222c-4be7-a357-69acf97e7fec"
      },
      "source": [
        "vote = []\n",
        "for i in range(len(true)):\n",
        "    vote.append(mode([df['flairFSent'].at[i],df['flairASent'].at[i],df['RobSent'].at[i]]))\n",
        "print(metrics.classification_report(true,vote))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.94      0.97      0.95     49986\n",
            "           1       0.97      0.93      0.95     50014\n",
            "\n",
            "    accuracy                           0.95    100000\n",
            "   macro avg       0.95      0.95      0.95    100000\n",
            "weighted avg       0.95      0.95      0.95    100000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVJDTyLa-YEC"
      },
      "source": [
        "# Conclusions:\n",
        "- From results we conclude that native models are more effective than stacking"
      ]
    }
  ]
}